{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "stu_name = 'Mana Abbaszadeh'\n",
        "stu_num = '400109638'"
      ],
      "metadata": {
        "id": "q4oEgtrsYWlK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1-izC4ZKHJ9"
      },
      "source": [
        "<h1 style=\"text-align: center\">\n",
        "Machine Learning </br>\n",
        "MLE & MAP in Python\n",
        "</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhTuYwHYbE_1"
      },
      "source": [
        "## Objective\n",
        "This exercise will help you gain a deeper understanding of, and insights into, Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP) estimation$\\textit{Maximum Likelihood Estimation (MLE) and Maximum A Posteriori (MAP) }$ :) \\\\\n",
        "Letâ€™s say you have a barrel of apples that are all different sizes. You pick an apple at random, and you want to know its weight. Unfortunately, all you have is a broken scale. answer the questions below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSaLb6AYa9DJ"
      },
      "source": [
        "1) For the sake of this section, lets imagine a farmer tells you that the scale returns the weight of the object with an error of +/- a standard deviation of 5g. We can describe this mathematically as:\n",
        "$$\n",
        "measurement = weight + \\mathcal{N}(0, 5g)\n",
        "$$\n",
        "You can weigh the apple as many times as you want, so weigh it 100 times.\n",
        "plot its histogram of your 100 measurements. (y axis is the counts and x-axis is the measured weight)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "GJqLsWvDbn0i"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hPMnHTcia07a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "a5398724-d280-4713-f023-d8664fe4a35f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "std = 5\n",
        "measure_times = 100\n",
        "real_apple_weight = 150  # Arbitrary\n",
        "measurements = np.random.normal(real_apple_weight, std, measure_times)\n",
        "plt.hist(measurements, bins=30, edgecolor='black')\n",
        "plt.xlabel('Measured Weight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HD9Mqy-bcPi5"
      },
      "source": [
        "2) Find the average weight of the apple.\n",
        "Is it a good guess? state your reason."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "xlCBTC0lcPKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f51feabb-ca6e-4f2d-c7cc-59183380d15f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "150.9316611881365\n"
          ]
        }
      ],
      "source": [
        "print(measurements.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-P9PJuKcrbq"
      },
      "source": [
        "3) we are going to use grid approximation for calculating the MLE. here is the link if you wnat to get more fimilar with this technique:\n",
        "https://www.bayesrulesbook.com/chapter-6\n",
        "\n",
        "Our end goal is to find the weight of the apple, given the data we have. To formulate it in a Bayesian way: Weâ€™ll ask what is the probability of the apple having weight, $w$, given the measurements we took, $X$. And, because we're formulating this in a Bayesian way, we use Bayesâ€™ Law to find the answer:\n",
        "\n",
        "$$\n",
        "P(w|X) = \\frac{P(X|w)P(w)}{P(X)}\n",
        "$$\n",
        "\n",
        "If we make no assumptions about the initial weight of our apple, then we can drop $P(w)$. Weâ€™ll say all sizes of apples are equally likely (weâ€™ll revisit this assumption in the MAP approximation).\n",
        "\n",
        "Furthermore, weâ€™ll drop $P(X)$ - the probability of seeing our data. This is a normalization constant and will be important if we do want to know the probabilities of apple weights. But, for right now, our end goal is to only to find the most probable weight. $P(X)$ is independent of $w$, so we can drop it if weâ€™re doing relative comparisons.\n",
        "\n",
        "This leaves us with $P(X|w)$, our likelihood, as in, what is the likelihood that we would see the data, $X$, given an apple of weight $w$. If we maximize this, we maximize the probability that we will guess the right weight.\n",
        "\n",
        "The grid approximation is probably the simplest way to do this. Basically, weâ€™ll systematically step through different weight guesses, and compare what it would look like if this hypothetical weight were to generate data. Weâ€™ll compare this hypothetical data to our real data and pick the one that matches the best.\n",
        "\n",
        "To formulate this mathematically:\n",
        "\n",
        "For each of these guesses, weâ€™re asking \"what is the probability that the data we have, came from the distribution that our weight guess would generate\". Because each measurement is independent from another, we can break the above equation down into finding the probability on a per measurement basis:\n",
        "\n",
        "$$\n",
        "P(X|w) = \\prod_{i}^{N} p(x_i|w)\n",
        "$$\n",
        "\n",
        "So, if we multiply the probability that we would see each individual data point - given our weight guess - then we can find one number comparing our weight guess to all of our data.\n",
        "\n",
        "The peak in the likelihood is the weight of the apple.\n",
        "\n",
        "To make it computationally easier,\n",
        "\n",
        "$$\n",
        "\\log P(X|w) = \\log \\prod_{i}^{N} p(x_i|w) = \\sum_{i}^{N} \\log p(d_i|w)\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "a) Why did we use log likelihood? Is it ok to do so?\n",
        "\n",
        "Answer: By using log we transform products to sums so the calculation becomes easier and faster. Usin larger datasets is no longer a problem. Using log likelihood is ok as it increases uniformly.\n",
        "\n",
        "b) do the grid approximation and complete the cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "9NnWmxzTiRfr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "aae33012-2708-47de-c9d3-82ed1101af4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Likelihood Estimation of the apple: 100.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nCalculate the maximum likelihood estimate of a parameter in a normal distribution.\\nFirst calculate the log likelihoods for a range of weight guesses.\\nFor each weight guess, assume that the data comes from a normal distribution with that mean and a standard deviation of 10.\\nThen calculate the log of the probability density function (pdf) of the data under this assumption.\\nThe sum of these log pdf values is the total log likelihood for that weight guess.\\nAfter calculating the log likelihoods for all weight guesses, find the weight guess with the maximum log likelihood.\\nThis is the maximum likelihood estimate of the weight.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "weight_grid = np.linspace(0, 100)\n",
        "\n",
        "likelihoods = []\n",
        "for weight in weight_grid:\n",
        "    log = np.sum(-0.5 * np.log(2 * np.pi * 5**2) - 0.5 * ((measurements - weight) / 5)**2)\n",
        "    likelihoods.append(log)\n",
        "ml_index = np.argmax(likelihoods)\n",
        "ml_weight = weight_grid[ml_index]\n",
        "print(f'Maximum Likelihood Estimation of the apple: {ml_weight}')\n",
        "\n",
        "'''\n",
        "Calculate the maximum likelihood estimate of a parameter in a normal distribution.\n",
        "First calculate the log likelihoods for a range of weight guesses.\n",
        "For each weight guess, assume that the data comes from a normal distribution with that mean and a standard deviation of 10.\n",
        "Then calculate the log of the probability density function (pdf) of the data under this assumption.\n",
        "The sum of these log pdf values is the total log likelihood for that weight guess.\n",
        "After calculating the log likelihoods for all weight guesses, find the weight guess with the maximum log likelihood.\n",
        "This is the maximum likelihood estimate of the weight.\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NN3lt2npcc2S"
      },
      "source": [
        "Play around with the code and try to answer the following questions regarding MLE and MAP. You can draw plots to visualize as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "ezcWTpNQamCL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3de77a38-1867-4d39-c33b-c830336158e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average measurement: 93.746 g\n",
            "Maximum Likelihood estimate: 151.758 g\n",
            "Maximum A Posterior estimate: 51.253 g\n",
            "The true weight of the apple was: 95.261 g\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.stats import norm, invgamma\n",
        "\n",
        "\n",
        "# The barrel of apples\n",
        "# The average apples is between 70-100 g\n",
        "BARREL = np.random.normal(loc=85, scale=20, size=100)\n",
        "# Grid\n",
        "WEIGHT_GUESSES = np.linspace(1, 200, 100)\n",
        "ERROR_GUESSES = np.linspace(.1, 50, 100)\n",
        "\n",
        "# NOTE: Try changing the scale error\n",
        "# in practice, you would not know this number\n",
        "SCALE_ERR = 5\n",
        "\n",
        "# NOTE: Try changing the number of measurements taken\n",
        "N_MEASURMENTS = 10\n",
        "\n",
        "# NOTE: Try changing the prior values and distributions\n",
        "PRIOR_WEIGHT = norm(50, 1).logpdf(WEIGHT_GUESSES)\n",
        "PRIOR_ERR = invgamma(4).logpdf(ERROR_GUESSES)\n",
        "\n",
        "LOG_PRIOR_GRID = np.add.outer(PRIOR_ERR, PRIOR_WEIGHT)\n",
        "\n",
        "\n",
        "def read_scale(apple):\n",
        "    return apple + np.random.normal(loc=0, scale=SCALE_ERR)\n",
        "\n",
        "\n",
        "def get_log_likelihood_grid(measurments):\n",
        "    log_liklelihood = [\n",
        "        [\n",
        "            norm(weight_guess, error_guess).logpdf(measurments).sum()\n",
        "            for weight_guess in WEIGHT_GUESSES\n",
        "        ]\n",
        "        for error_guess in ERROR_GUESSES\n",
        "    ]\n",
        "    return np.asarray(log_liklelihood)\n",
        "\n",
        "\n",
        "def get_mle(measurments):\n",
        "    grid = get_log_likelihood_grid(measurements)\n",
        "    # Maximum value in the flattened array\n",
        "    max_val = np.argmax(grid, axis=None)\n",
        "    ml_weight = np.unravel_index(max_val, grid.shape)\n",
        "    return WEIGHT_GUESSES[ml_weight[1]]\n",
        "\n",
        "    \"\"\"\n",
        "    Calculate the log-likelihood for each measurement in the grid.\n",
        "    Find the index of the maximum log-likelihood in the grid.\n",
        "    Return the weight guess corresponding to the maximum log-likelihood.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "def get_map(measurements):\n",
        "    grid = get_log_likelihood_grid(measurements)\n",
        "    post_grid = LOG_PRIOR_GRID + grid\n",
        "    max_val = np.argmax(post_grid, axis=None)\n",
        "    map_weight = np.unravel_index(max_val, post_grid.shape)\n",
        "    return WEIGHT_GUESSES[map_weight[1]]\n",
        "\n",
        "    \"\"\"\n",
        "    Calculate the log-likelihood for each measurement in the grid.\n",
        "    Add the log prior to the log likelihood to get the log posterior.\n",
        "    Find the index of the maximum log posterior in the grid.\n",
        "    Return the weight guess corresponding to the maximum log posterior.\n",
        "    \"\"\"\n",
        "\n",
        "# Pick an apple at random\n",
        "apple = np.random.choice(BARREL)\n",
        "\n",
        "# weight the apple\n",
        "measurments = np.asarray([read_scale(apple) for _ in range(N_MEASURMENTS)])\n",
        "\n",
        "print(f\"Average measurement: {measurments.mean():.3f} g\")\n",
        "print(f\"Maximum Likelihood estimate: {get_mle(measurments):.3f} g\")\n",
        "print(f\"Maximum A Posterior estimate: {get_map(measurments):.3f} g\")\n",
        "print(f\"The true weight of the apple was: {apple:.3f} g\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Change the scale error:"
      ],
      "metadata": {
        "id": "EHf6FmVplwCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BARREL = np.random.normal(loc=85, scale=20, size=100)\n",
        "# Grid\n",
        "WEIGHT_GUESSES = np.linspace(1, 200, 100)\n",
        "ERROR_GUESSES = np.linspace(.1, 50, 100)\n",
        "\n",
        "# NOTE: Try changing the scale error\n",
        "# in practice, you would not know this number\n",
        "SCALE_ERR = 10\n",
        "\n",
        "# NOTE: Try changing the number of measurements taken\n",
        "N_MEASURMENTS = 10\n",
        "\n",
        "# NOTE: Try changing the prior values and distributions\n",
        "PRIOR_WEIGHT = norm(50, 1).logpdf(WEIGHT_GUESSES)\n",
        "PRIOR_ERR = invgamma(4).logpdf(ERROR_GUESSES)\n",
        "\n",
        "LOG_PRIOR_GRID = np.add.outer(PRIOR_ERR, PRIOR_WEIGHT)\n",
        "\n",
        "# Pick an apple at random\n",
        "apple = np.random.choice(BARREL)\n",
        "\n",
        "# weight the apple\n",
        "measurments = np.asarray([read_scale(apple) for _ in range(N_MEASURMENTS)])\n",
        "\n",
        "print(f\"Average measurement: {measurments.mean():.3f} g\")\n",
        "print(f\"Maximum Likelihood estimate: {get_mle(measurments):.3f} g\")\n",
        "print(f\"Maximum A Posterior estimate: {get_map(measurments):.3f} g\")\n",
        "print(f\"The true weight of the apple was: {apple:.3f} g\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26ZTKCEZlepi",
        "outputId": "8d55bcf3-15bb-4b55-e3b1-78cd8d96e92e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average measurement: 95.719 g\n",
            "Maximum Likelihood estimate: 151.758 g\n",
            "Maximum A Posterior estimate: 51.253 g\n",
            "The true weight of the apple was: 96.886 g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Change the grid size:"
      ],
      "metadata": {
        "id": "cSRepk_yl9gF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BARREL = np.random.normal(loc=85, scale=20, size=100)\n",
        "# Grid\n",
        "WEIGHT_GUESSES = np.linspace(1, 200, 150)\n",
        "ERROR_GUESSES = np.linspace(.1, 50, 150)\n",
        "\n",
        "# NOTE: Try changing the scale error\n",
        "# in practice, you would not know this number\n",
        "SCALE_ERR = 5\n",
        "\n",
        "# NOTE: Try changing the number of measurements taken\n",
        "N_MEASURMENTS = 10\n",
        "\n",
        "# NOTE: Try changing the prior values and distributions\n",
        "PRIOR_WEIGHT = norm(50, 1).logpdf(WEIGHT_GUESSES)\n",
        "PRIOR_ERR = invgamma(4).logpdf(ERROR_GUESSES)\n",
        "\n",
        "LOG_PRIOR_GRID = np.add.outer(PRIOR_ERR, PRIOR_WEIGHT)\n",
        "\n",
        "# Pick an apple at random\n",
        "apple = np.random.choice(BARREL)\n",
        "\n",
        "# weight the apple\n",
        "measurments = np.asarray([read_scale(apple) for _ in range(N_MEASURMENTS)])\n",
        "\n",
        "print(f\"Average measurement: {measurments.mean():.3f} g\")\n",
        "print(f\"Maximum Likelihood estimate: {get_mle(measurments):.3f} g\")\n",
        "print(f\"Maximum A Posterior estimate: {get_map(measurments):.3f} g\")\n",
        "print(f\"The true weight of the apple was: {apple:.3f} g\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avepkbxll0vI",
        "outputId": "e4ca54e0-af82-45ab-8eac-7607b915c54c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average measurement: 79.304 g\n",
            "Maximum Likelihood estimate: 150.584 g\n",
            "Maximum A Posterior estimate: 50.416 g\n",
            "The true weight of the apple was: 76.194 g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Change the prior values and distributionsv (mean and std_dev):"
      ],
      "metadata": {
        "id": "QTGZL3ZgnEZ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BARREL = np.random.normal(loc=85, scale=20, size=100)\n",
        "# Grid\n",
        "WEIGHT_GUESSES = np.linspace(1, 200, 100)\n",
        "ERROR_GUESSES = np.linspace(.1, 50, 100)\n",
        "\n",
        "# NOTE: Try changing the scale error\n",
        "# in practice, you would not know this number\n",
        "SCALE_ERR = 5\n",
        "\n",
        "# NOTE: Try changing the number of measurements taken\n",
        "N_MEASURMENTS = 10\n",
        "\n",
        "# NOTE: Try changing the prior values and distributions\n",
        "PRIOR_WEIGHT = norm(20, 2).logpdf(WEIGHT_GUESSES)\n",
        "PRIOR_ERR = invgamma(4).logpdf(ERROR_GUESSES)\n",
        "\n",
        "LOG_PRIOR_GRID = np.add.outer(PRIOR_ERR, PRIOR_WEIGHT)\n",
        "\n",
        "# Pick an apple at random\n",
        "apple = np.random.choice(BARREL)\n",
        "\n",
        "# weight the apple\n",
        "measurments = np.asarray([read_scale(apple) for _ in range(N_MEASURMENTS)])\n",
        "\n",
        "print(f\"Average measurement: {measurments.mean():.3f} g\")\n",
        "print(f\"Maximum Likelihood estimate: {get_mle(measurments):.3f} g\")\n",
        "print(f\"Maximum A Posterior estimate: {get_map(measurments):.3f} g\")\n",
        "print(f\"The true weight of the apple was: {apple:.3f} g\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dAyI0skmHHZ",
        "outputId": "ca8ec4bf-c420-49f3-c414-1fe3a5b42ab1"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average measurement: 103.693 g\n",
            "Maximum Likelihood estimate: 151.758 g\n",
            "Maximum A Posterior estimate: 21.101 g\n",
            "The true weight of the apple was: 102.682 g\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LI_541TpetKk"
      },
      "source": [
        "<h3><i><i> Questions</h3>\n",
        "1.\n",
        "How sensitive is the MAP measurement to the choice of prior?\n",
        "\n",
        "Answer:\n",
        "\n",
        "The sensitivity of Maximum A Posteriori (MAP) estimation to the choice of prior depends on many factors such as the distribution of the likelihood, the strength of the prior information or the amount of available data. For instance informative likelihoods reduce sensitivity. On the other hand, strong priors or limited data increase sensitivity."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMV-wgYXes_O"
      },
      "source": [
        "<h3><i><i></h3>\n",
        "2. How sensitive is the MLE and MAP answer to the grid size?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Both MLEA and MAP are sensitive to the grid size but MAP is more sensitive. THE bigger the grid size and the finer the grid, the more accurate MAP and MLE estimates will be. However, increasing the grid size also comes with computational costs, so it's important to make a balance between accuracy and computational efficiency.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}